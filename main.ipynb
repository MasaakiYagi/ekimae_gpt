{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import wave\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pyaudio\n",
    "import pyttsx3\n",
    "\n",
    "import openai\n",
    "\n",
    "import os\n",
    "import re\n",
    "import keyboard\n",
    "from transitions import Machine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT        = pyaudio.paInt16\n",
    "SAMPLE_RATE   = 44100        # サンプリングレート\n",
    "CHANNELS      = 1            # モノラルかバイラルか\n",
    "INPUT_DEVICE_INDEX = 0       # マイクのチャンネル\n",
    "CALL_BACK_FREQUENCY = 3      # コールバック呼び出しの周期[sec]\n",
    "\n",
    "\n",
    "OUTPUT_TXT_FILE = \"./\" + datetime.now().strftime('%Y%m%d_%H_%M') +\".txt\" # テキストファイルのファイル名を日付のtxtファイルにする\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    \"\"\"\n",
    "    コールバック関数の定義\n",
    "    \"\"\"\n",
    "    \n",
    "    global sprec # speech_recognitionオブジェクトを毎回作成するのではなく、使いまわすために、グローバル変数で定義しておく\n",
    "\n",
    "    try:\n",
    "        audiodata  = sr.AudioData(in_data, SAMPLE_RATE, 2)\n",
    "        sprec_text = sprec.recognize_google(audiodata, language='ja-JP')\n",
    "        \n",
    "        with open(OUTPUT_TXT_FILE,'a') as f: #ファイルの末尾に追記していく\n",
    "            f.write(\"\\n\" + sprec_text)\n",
    "    \n",
    "    except sr.UnknownValueError:\n",
    "        pass\n",
    "    \n",
    "    except sr.RequestError as e:\n",
    "        pass\n",
    "    \n",
    "    finally:\n",
    "        return (None, pyaudio.paContinue)\n",
    "\n",
    "\n",
    "def realtime_textise():\n",
    "    \"\"\"\n",
    "    リアルタイムで音声を文字起こしする\n",
    "    \"\"\"\n",
    "\n",
    "    with open(OUTPUT_TXT_FILE, 'w') as f: #txtファイルの新規作成\n",
    "        DATE = datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "        f.write(\"日時 : \" + DATE + \"\\n\") # 最初の一行目に日時を記載する\n",
    "\n",
    "    global sprec # speech_recognitionオブジェクトを毎回作成するのではなく、使いまわすために、グローバル変数で定義しておく\n",
    "    \n",
    "    # speech recogniserインスタンスを生成\n",
    "    sprec = sr.Recognizer() \n",
    "    \n",
    "    # Audio インスタンス取得\n",
    "    audio  = pyaudio.PyAudio() \n",
    "    \n",
    "    # ストリームオブジェクトを作成\n",
    "    stream = audio.open(format             = FORMAT,\n",
    "                        rate               = SAMPLE_RATE,\n",
    "                        channels           = CHANNELS,\n",
    "                        input_device_index = INPUT_DEVICE_INDEX,\n",
    "                        input              = True, \n",
    "                        frames_per_buffer  = SAMPLE_RATE*CALL_BACK_FREQUENCY, # CALL_BACK_FREQUENCY 秒周期でコールバック\n",
    "                        stream_callback    = callback)\n",
    "    \n",
    "    stream.start_stream()\n",
    "    \n",
    "    try:\n",
    "        while stream.is_active():\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"end\")\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "\n",
    "def main():\n",
    "    #look_for_audio_input()\n",
    "    realtime_textise()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat-GPT\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "class ekimaeGPT:\n",
    "    def __init__(self) -> None:\n",
    "        # ChatGPTの設定\n",
    "        openai.api_key = API_KEY\n",
    "        self.pattern =re.compile(r'[a-z]+:')\n",
    "        \n",
    "        # 発話機能の設定\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.voices = self.engine.getProperty('voices')\n",
    "        self.engine.setProperty(\"voice\", self.voices[1].id)\n",
    "        \n",
    "        # AudioListenerの設定\n",
    "        self.FORMAT        = pyaudio.paInt16\n",
    "        self.SAMPLE_RATE   = 44100        # サンプリングレート\n",
    "        self.CHANNELS      = 1            # モノラルかバイラルか\n",
    "        self.INPUT_DEVICE_INDEX = 3       # マイクのチャンネル\n",
    "        self.CALL_BACK_FREQUENCY = 0.1\n",
    "        self.REFLESH_RATE = 100 / 1000\n",
    "        self.sprec = sr.Recognizer() \n",
    "        self.audio  = pyaudio.PyAudio()\n",
    "        self.inputwave = []\n",
    "        self.end_flag = 0\n",
    "\n",
    "    def request2gpt(self, request_text):\n",
    "        start_sequence = \"\\nAI:\"\n",
    "        restart_sequence = \"\\nHuman: \"\n",
    "\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=\"Human: \"+request_text,\n",
    "            temperature=0.9,\n",
    "            max_tokens=150,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "            stop=[\" Human:\", \" AI:\"]\n",
    "        )\n",
    "\n",
    "        response_text = response['choices'][0]['text'].replace('\\n', '').replace('Robot: ', '')\n",
    "        response_text = self.pattern.sub('', response_text)\n",
    "        return response_text\n",
    "    \n",
    "    def speech(self, text):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "    \n",
    "    def talk2gpt(self, request_text):\n",
    "        res = self.request2gpt(request_text)\n",
    "        print(res)\n",
    "        self.speech(res)\n",
    "    \n",
    "    def start_pyaudio(self):\n",
    "        # 状態がlisteningに移ったときに実行\n",
    "        # 並列で録音開始、\n",
    "        self.end_flag = 1\n",
    "        self.inputwave = []\n",
    "        self.stream = self.audio.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.SAMPLE_RATE,\n",
    "            input_device_index = self.INPUT_DEVICE_INDEX,\n",
    "            input=True,\n",
    "            frames_per_buffer=int(self.SAMPLE_RATE*self.CALL_BACK_FREQUENCY),\n",
    "            stream_callback=self.audio_callback\n",
    "        )\n",
    "        self.stream.start_stream()\n",
    "        print(\"start rec\")\n",
    "        \n",
    "        \n",
    "    def start_process(self):\n",
    "        # listeningが終了しprocessに移ったときに実行\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        print(\"end rec\")\n",
    "        \n",
    "        try:\n",
    "            print(\"start trans\")\n",
    "            audiodata  = sr.AudioData(b''.join(self.inputwave), self.SAMPLE_RATE, 2)\n",
    "            print(audiodata)\n",
    "            sprec_text = self.sprec.recognize_google(audiodata, language='en-US')\n",
    "            #sprec_text = \"Hi, I'm Kenji.\"\n",
    "            print(sprec_text)\n",
    "            self.talk2gpt(sprec_text)\n",
    "            #self.res()  # 状態をidleに戻す\n",
    "            self.end_flag = 0\n",
    "        \n",
    "        except sr.UnknownValueError:\n",
    "            print(sr.UnknownValueError)\n",
    "            self.end_flag = 0\n",
    "        \n",
    "        except sr.RequestError as e:\n",
    "            print(e)\n",
    "            self.end_flag = 0\n",
    "        \n",
    "        finally:\n",
    "            return (None, pyaudio.paContinue)\n",
    "    \n",
    "    def audio_callback(self, in_data, frame_count, time_info, status_flags):\n",
    "        self.inputwave.append(in_data)\n",
    "        if self.state!=\"listening\":\n",
    "            return None, pyaudio.paComplete\n",
    "        return None, pyaudio.paContinue\n",
    "    \n",
    "    def callback(self):\n",
    "        # サンプリングレート毎に実行する処理\n",
    "        #print(\"status: \" + self.state, end=\"\")\n",
    "        pass\n",
    "    \n",
    "    def activate(self):\n",
    "        # 実行\n",
    "        while self.exit_flag==0:\n",
    "            self.callback()\n",
    "            time.sleep(self.REFLESH_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34A90>\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.97200739,\n",
      "                           'transcript': 'hi nice to meet you'},\n",
      "                       {'transcript': 'hi nice to meet'}],\n",
      "    'final': True}\n",
      "hi nice to meet you\n",
      "B Hi there! It's nice to meet you too!\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34A60>\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.95891434,\n",
      "                           'transcript': \"what's your name\"},\n",
      "                       {'transcript': 'what your name'},\n",
      "                       {'transcript': \"what's her name\"},\n",
      "                       {'transcript': \"what's a name\"},\n",
      "                       {'transcript': 'what you name'}],\n",
      "    'final': True}\n",
      "what's your name\n",
      "B My name is Bot.\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34580>\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.97219545,\n",
      "                           'transcript': 'okay can I call you'},\n",
      "                       {'transcript': 'okay can I call you about'},\n",
      "                       {'transcript': 'okay can I call you a'},\n",
      "                       {'transcript': 'okay can I call you but'},\n",
      "                       {'transcript': 'okay can I call you back'}],\n",
      "    'final': True}\n",
      "okay can I call you\n",
      " JoeySure.\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34A60>\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.96245438,\n",
      "                           'transcript': \"okay and I'd like to improve my \"\n",
      "                                         'English speaking skills can you '\n",
      "                                         'accompany me in English '\n",
      "                                         'conversation'},\n",
      "                       {   'transcript': \"okay and I'd like to improve my \"\n",
      "                                         'English speaking skills can you '\n",
      "                                         'accompany me in English convers'},\n",
      "                       {   'transcript': \"okay and I'd like to improve my \"\n",
      "                                         'English-speaking skills can you '\n",
      "                                         'accompany me in English '\n",
      "                                         'conversation'},\n",
      "                       {   'transcript': 'okay and I drive to improve my '\n",
      "                                         'English speaking skills can you '\n",
      "                                         'accompany me in English '\n",
      "                                         'conversation'},\n",
      "                       {   'transcript': \"okay and I'd like to improve my \"\n",
      "                                         'English-speaking skills can you '\n",
      "                                         'accompany me in English convers'}],\n",
      "    'final': True}\n",
      "okay and I'd like to improve my English speaking skills can you accompany me in English conversation\n",
      "Absolutely! I would be happy to help you learn and improve your English conversation skills.\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34580>\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.97219551,\n",
      "                           'transcript': 'thank you what do you do for me'}],\n",
      "    'final': True}\n",
      "thank you what do you do for me\n",
      "I can help you with a variety of tasks, from answering questions to helping you find information.\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34BE0>\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.83563668, 'transcript': 'okay'},\n",
      "                       {'transcript': 'ok'}],\n",
      "    'final': True}\n",
      "okay\n",
      "What would you like to talk about?\n",
      "start rec\n",
      "end rec\n",
      "start trans\n",
      "<speech_recognition.AudioData object at 0x0000021F0EB34580>\n",
      "result2:\n",
      "{   'alternative': [{'confidence': 0.97219545, 'transcript': 'nothing'}],\n",
      "    'final': True}\n",
      "nothing\n",
      "C Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "states = [\"idle\", \"listening\", \"process\", \"end\"]\n",
    "transitions = [\n",
    "    {\"trigger\": \"start_listen\", \"source\": \"idle\", \"dest\": \"listening\", \"before\": \"start_pyaudio\"},\n",
    "    {\"trigger\": \"end_listen\", \"source\": \"listening\", \"dest\": \"process\", \"before\": \"start_process\"},\n",
    "    {\"trigger\": \"res\", \"source\": \"process\", \"dest\": \"idle\"},\n",
    "    {\"trigger\": \"idle2quit\", \"source\": \"idle\", \"dest\": \"end\"},\n",
    "    {\"trigger\": \"process2quit\", \"source\": \"process\", \"dest\": \"end\"},\n",
    "]\n",
    "\n",
    "gptkun = ekimaeGPT()\n",
    "machine = Machine(model=gptkun, states=states, transitions=transitions, initial='idle', auto_transitions=False)\n",
    "\n",
    "while gptkun.state != \"end\":\n",
    "    if keyboard.is_pressed(\"q\"):  # qが押されているとき\n",
    "        if gptkun.state == \"idle\":  # idleだったら終了\n",
    "            gptkun.idle2quit()\n",
    "        elif gptkun.state == \"process\":  # processでも終了\n",
    "            gptkun.process2quit()\n",
    "    elif keyboard.is_pressed(\"space\"):  # spaceが押されているとき\n",
    "        if gptkun.state == \"idle\":  # もともとidleだったらlisteningに遷移\n",
    "            gptkun.start_listen()\n",
    "    else:  # 何もキーが押されていないとき\n",
    "        if gptkun.state == \"listening\":  # listening中だったらlistening終了\n",
    "            gptkun.end_listen()\n",
    "        elif gptkun.end_flag == 0 and gptkun.state == \"process\":\n",
    "            gptkun.res()\n",
    "    gptkun.callback()\n",
    "    time.sleep(gptkun.REFLESH_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ekimae_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba7778e17e40e31ca71f470042a900c771cd58ce876794db41436c6e68809f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
